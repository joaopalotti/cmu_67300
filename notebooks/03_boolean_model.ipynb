{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# We start by assuming that the inverted index and document map were correctly created in the HW1.\n",
    "### (A similar code to the one below was used in notebook 2 to create a simple inverted index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# A sample function breaks a text into a list of tokens\n",
    "import re\n",
    "\n",
    "def tokenize(text):\n",
    "    text = re.sub(\"\\W\", \" \", text)\n",
    "    text = ' '.join(text.split())\n",
    "    tokens = text.lower().split()\n",
    "    return tokens\n",
    "\n",
    "doc1 = \"this is a small document\"\n",
    "doc2 = \"this is another document, but larger.\"\n",
    "doc3 = \"Compared to the other two documents, this one is huuuuuge!\"\n",
    "doc4 = \"qatar is a country located in the middle west\"\n",
    "doc5 = \"qatar is 6 hours ahead of brazil\"\n",
    "docmap = {\"doc1\":1, \"doc2\":2, \"doc3\":3, \"doc4\":4, \"doc5\":5}\n",
    "# the inverted index for the documents above as well as the docmap was saved to disk in the first HW.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Reads file iindex.map from hard drive into RAM memory\n",
    "iindex = {}\n",
    "with open(\"iindex.map\", \"r\") as f:\n",
    "    for line in f.readlines():\n",
    "        fields = line.strip().split(\",\")\n",
    "        token = fields[0]\n",
    "        freqs = fields[1:]\n",
    "        iindex[token] = {}\n",
    "        for f in freqs:\n",
    "            docid, freq = f.split(\":\")\n",
    "            iindex[token][int(docid)] = int(freq)\n",
    "iindex "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "docmap = {}\n",
    "with open(\"docs.map\",\"r\") as f:\n",
    "    for line in f.readlines():\n",
    "        w, c = line.strip().split(\",\")\n",
    "        docmap[int(c)] = w # NOTE THAT WE ARE NOW SWAPPING THE DOCUMENT NAME AND THE DOCUMENT ID\n",
    "docmap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# First model: Boolean Search\n",
    "\n",
    "#### Let's start by implementing a OR search:\n",
    "Query: small document -> small OR document\n",
    "Query: brazil document -> brazil OR document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "query = \"small document\"\n",
    "\n",
    "def prepare_query(query):\n",
    "    tokens = query.lower().split()\n",
    "    # Remember that some operations like stemming HAVE TO be applied to the query as we did to the text \n",
    "    # You might also want to remove stopwords, lower case tokens, etc...\n",
    "    return tokens\n",
    "\n",
    "keywords = prepare_query(query)\n",
    "\n",
    "# result_set starts as an empty set\n",
    "result_set = set([])\n",
    "\n",
    "for word in keywords:\n",
    "    # \n",
    "    result_set = result_set.union(iindex[word].keys())\n",
    "    print \"Found `%s` in %s\" % (word, iindex[word].keys())\n",
    "    \n",
    "print result_set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's try now to implement an AND search:\n",
    "Query: small document -> small AND document\n",
    "Query: brazil document -> brazil AND document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "query = \"small document\"\n",
    "\n",
    "def prepare_query(query):\n",
    "    tokens = query.lower().split()\n",
    "    # Remember that some operations like stemming HAVE TO be applied to the query as we did to the text \n",
    "    # You might also want to remove stopwords, lower case tokens, etc...\n",
    "    return tokens\n",
    "\n",
    "keywords = prepare_query(query)\n",
    "\n",
    "result_set = set(iindex[keywords[0]].keys())\n",
    "print \"Found `%s` in %s\" % (keywords[0], iindex[keywords[0]].keys())\n",
    "\n",
    "for word in keywords[1:]:\n",
    "    result_set = result_set.intersection(iindex[word].keys())\n",
    "    print \"Found `%s` in %s\" % (word, iindex[word].keys())\n",
    "    \n",
    "print result_set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The two programs above are very simple. \n",
    "You can have a more challenge code if you allow your query language to support more operators. \n",
    "For example, what if AND, OR and NOT are query operators?\n",
    "\n",
    "Query: \"lincoln AND president AND (biography OR life OR birthplace OR gettysburg) AND NOT(automobile OR car)\"\n",
    "\n",
    "###### Hint: check the python library sympy\n",
    "\n",
    "\n",
    "----------------------------------------------------------------------------------------------------\n",
    "----------------------------------------------------------------------------------------------------\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the homework 2, you will have to implement some search models.\n",
    "Additional information that is not currently being stored in the iindex and docmap need to be saved.\n",
    "\n",
    "\n",
    "Summary:\n",
    "\n",
    "VSM: TF-IDF...\n",
    "--> IDF: We need IDF for each term, can be pre-processed and kept in the iindex.\n",
    "--> Document Length: check normalization formula!\n",
    "\n",
    "BM25: \n",
    "--> Ld: We need document length again (simpler to calculate this time) -- Can you see the difference between this document length and the one used in VSM?\n",
    "--> Lavg: the average size of documents in our collection\n",
    "\n",
    "LM:\n",
    "--> Ld: document length. Same used in BM25\n",
    "\n",
    "----------------------------------------------------------------------------------------------------\n",
    "----------------------------------------------------------------------------------------------------\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
